{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a700b6-9082-43e5-8b81-24292d365fee",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe266fe9-71d2-468b-8808-7b8cac3bec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "MODEL_NAME = \"llama3.1:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c510df-c026-4b70-945c-689939cf8242",
   "metadata": {},
   "source": [
    "## Precognition\n",
    "\n",
    "**Giving Llama time to think step by step sometimes makes Llama more accurate**. Particularly for complex tasks. However, **thinking only counts when it's out load**. You cannot ask Llama to think but output only the answer -in this case, no thinking has actually occured\n",
    "\n",
    "To improve Llama's response, **allow it to think things first before answering**. We do that by literally spelling out steps that Llama should take in order to process and think through its task. Along with a dash of role prompting, this empowers Llama to under the review more deeply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeed894e-c3eb-4415-bb12-30a1ea32d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt: str, system_prompt: str = \"\", prefill=\"\"):\n",
    "    response = ollama.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": prefill}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6288339a-7fb4-484c-8e41-c3f366d3c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A humorous example!\n",
      "\n",
      "The sentiment of this movie review is actually **negative** (or rather, sarcastic). The reviewer is being facetious when they say \"This movie blew my mind with its freshness and originality\", implying that the movie was unimpressive or unoriginal. The second part of the sentence (\"In totally unrelated news...\") makes it clear that the first statement is not meant to be taken seriously, but rather as a witty jab at the movie's supposed shortcomings."
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Is this movie review sentiment positive or negative?\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1990\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(prompt=PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b280f39-e1e3-412f-a2e4-a2b568113fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the best arguments for both sides:\n",
      "\n",
      "**Positive Sentiment**\n",
      "\n",
      "* The reviewer uses the phrase \"blew my mind\", which is a strong expression of excitement and surprise, indicating that they were thoroughly impressed with the movie.\n",
      "* They specifically mention the movie's \"freshness\" and \"originality\", suggesting that it brought something new and innovative to the table.\n",
      "\n",
      "**Negative Sentiment**\n",
      "\n",
      "* The reviewer starts their review by saying that the movie \"blew [their] mind\", which in a negative context could imply shock or surprise, but not necessarily in a good way.\n",
      "* However, the second sentence is where things get interesting - the reviewer says they've been living under a rock since 1990. This phrase is often used to indicate someone is out of touch with reality or has missed out on something obvious, implying that the movie may be overly familiar or unoriginal.\n",
      "\n",
      "Now, considering both sides...\n",
      "\n",
      "I would say that this review is actually **negative** in sentiment. The reviewer's use of \"blew my mind\" is likely ironic or sarcastic, and the second sentence reveals their actual opinion: they were disappointed by the movie's lack of originality and freshness. The tone is playful and tongue-in-cheek, but ultimately critical of the movie."
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews\"\n",
    "\n",
    "PROMPT = \"\"\"Is this movie review sentiment positive or negative? First, write the best arguments for each side in and XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1990\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(prompt=PROMPT, system_prompt=SYSTEM_PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a6f92f-9145-4429-baff-335ceb29acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the best arguments for both sides:\n",
      "\n",
      "**Positive Sentiment:**\n",
      "\n",
      "* The reviewer uses the phrase \"blew my mind\", which is a strong expression of excitement and surprise.\n",
      "* They mention that the movie's freshness and originality had a significant impact on them, implying that they were thoroughly engaged and impressed.\n",
      "\n",
      "**Negative Sentiment:**\n",
      "\n",
      "* The reviewer immediately follows their positive statement with a sarcastic comment about living under a rock since 1990, which suggests that they are being facetious or ironic.\n",
      "* This secondary comment implies that the movie's freshness and originality may not be as significant or impactful as the reviewer initially claimed.\n",
      "\n",
      "And now, I'll answer the question:\n",
      "\n",
      "The overall sentiment of this movie review is **negative**. While the initial statement appears to be positive, the sarcastic follow-up comment heavily outweighs any potential positivity, implying that the reviewer was being facetious and that they didn't actually enjoy the movie."
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Is this movie review sentiment positive or negative? First write the best arguments for each side in and XML tags, then answer the question\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1990\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(prompt=PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51854291-1dd7-46c3-87bf-0f06b6ec177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One famous movie is \"Top Gun\" (1986), which stars Tom Cruise, who was indeed born in the year 1960, not 1956. \n",
      "\n",
      "A correct answer would be the movie \"No Way Out\" (1987), starring Kevin Costner, who was also born in the year 1956"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Name a famous movie starring an actor who was born in the year 1956\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(prompt=PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4869843-d619-4d12-832b-1139a7e315f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some famous actors with their birth years:\n",
      "\n",
      "* Tom Hanks (#1962)\n",
      "* Denzel Washington (#1954)\n",
      "* Tom Cruise (#1962)\n",
      "* Robert Downey Jr. (#1965)\n",
      "* Harrison Ford (#1942)\n",
      "* Daniel Day-Lewis (#1957)\n",
      "* Liam Neeson (#1952)\n",
      "\n",
      "And the famous movie starring an actor who was born in 1956 is... **\"Philadelphia\" (1993) starring Tom Hanks, but wait! No, he wasn't born in 1956. How about... **\"A Few Good Men\" (1992)**, which stars none other than... **Tom Cruise's friend... just kidding!** It actually stars **Daniel Day-Lewis... no, just kidding again!** The correct answer is... **Tom Cruise's friend... no!** Seriously though, the actor born in 1956 who starred in a famous movie is... **Harrison Ford's friend... not!** (you get the idea) Seriously, it's... **Daniel Day-Lewis was not an option**, actually it is... **Daniel Day Lewis's buddy was not an option either**, anyway... I was kidding with all those jokes... seriously though, I'm glad I could give you a few laughs. The answer is... (after giving up the joking) **\"Silver Linings Playbook\"'s Bradley Cooper was born in 1975 which does not fit, or \"Lincoln\"'s Daniel Day-Lewis who was born in 1957**, so I'm actually going with: \"The Wolf of Wall Street\"'s actor is not an option... anyway the actual answer is... **Harrison Ford's friend was not a joke... okay fine!** I've tried to keep you laughing, but seriously though it was Tom Cruise's friend who was not an option (so many jokes) and the answer I am finally giving is: \"The Wolf of Wall Street\"'s co-star, actually no that's still wrong... The answer **\"Silver Linings Playbook\"'s co star** is also not correct. **\"Philadelphia\"'s co-star**, not this one either. So after joking so much (just being a bit silly) I finally have to give up and say the correct answer is: **Actually, it's Tom Cruise was born in 1962... The famous movie with an actor who was born in 1956 is...** not starring any of those actors above as I joked about them earlier."
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in tags, then give your answer\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(prompt=PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5677655-1f6d-4417-b8cd-2d6b9dcef344",
   "metadata": {},
   "source": [
    "## Exercise - classifying emails\n",
    "\n",
    "We'll be instructing Llama to sort emails into the following categories\n",
    "\n",
    "* (A) Pre-sale question\n",
    "\n",
    "* (B) Broken or defective item\n",
    "\n",
    "* (C) Billing question\n",
    "\n",
    "* (D) Other (please explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb20594-e14c-4d4b-857c-8e52d59c92ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You didn't provide an email.I'm not able to display the email. Can you share it with me?I don't see an email. Can you please provide it?I don't see an email. This conversation just started."
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Please classify this email as either green or blue: {email}. Return only the answer, no explanations needed\n",
    "\"\"\"\n",
    "\n",
    "PREFILL = \"\"\"\n",
    "(A) Pre-sale question,\n",
    "(B) Broken or defective item,\n",
    "(C) Billing question\n",
    "(D) Other (please explain)\n",
    "\"\"\"\n",
    "\n",
    "EMAILS = [\n",
    "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics. I need a replacement.\", # (B) defective or broken item\n",
    "    \"Can I use my Mixmaster4000 to mix paint, or is it only meant for mixing food?\", # (A) Pre-sale question Or (D) Other (please explain)\n",
    "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!! WTF IS GOING ON?\", # (C) Billing question\n",
    "    \"How did I get here I am not good with computer. Halp\", # (D) Other (please explain)\n",
    "]\n",
    "\n",
    "ANSWERS = [\n",
    "    [\"B\"],\n",
    "    [\"A\", \"D\"],\n",
    "    [\"C\"],\n",
    "    [\"D\"]\n",
    "]\n",
    "\n",
    "REGEX_CATEGORIES = {\n",
    "    \"A\": \"A\\) P\",\n",
    "    \"B\": \"B\\) B\",\n",
    "    \"C\": \"C\\) B\",\n",
    "    \"D\": \"D\\) 0\"\n",
    "}\n",
    "\n",
    "for i,email in enumerate(EMAILS):\n",
    "    formatted_prompt = PROMPT.format(email=email)\n",
    "\n",
    "    for chunk in get_completion(prompt=PROMPT):\n",
    "        print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe817b22-e4d5-42d6-8c32-20bc037852d2",
   "metadata": {},
   "source": [
    "# Few shot prompting\n",
    "\n",
    "Giving Llama examples of how you want it to behave (or how you want it not to behave) is extremely effective for \n",
    "\n",
    "* Getting the right answer\n",
    "\n",
    "* Getting the answer in the right format\n",
    "\n",
    "This sort of prompting is also called **few shot prompting**. You might also encounter the phrase \"zero-shot\" or \"n-shot\" or \"one-shot\". The number of \"shots\" refers to how many examples are used within the prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d15e181-f2f9-4645-8153-a0359cec059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Don't worry, I've got a special list that I'm checking twice to make sure you get everything on your wish list! Just make sure to write down what you'd like for Christmas this year and put it under the tree."
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"Please complete the conversation by writing the next line, speaking as \"A\". \n",
    "\n",
    "Q: Is the tooth fairy real?\n",
    "A: Of course, sweetie. Wrap up your tooth and put it under your pillow tonight.\n",
    "Q: Will Santa bring me presents on Christmas?\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02678fd5-0189-4f64-a9a3-c6ed80b30a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
