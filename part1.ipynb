{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d5304a-7c5a-46b8-875a-d9fea0e422c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! üëã  How can I help you today? üòä \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "MODEL_NAME = \"gemma2:2b\"\n",
    "\n",
    "def get_completion(prompt: str):\n",
    "    message = ollama.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message['message']['content']\n",
    "\n",
    "prompt = \"Hello, Claude\"\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66bb93c-b035-4d04-b856-e9f0eebe0663",
   "metadata": {},
   "source": [
    "# Basic Prompt Structure\n",
    "\n",
    "Each input message must be an object with a `role` and `content`. You can specify a single `user`-role message, or you can include multiple `user` and `assistant` messages (they must alternate, if so). The first message must always use the user `role`.\n",
    "\n",
    "`user` and `assistant` messages **must alternate**, and messages **must start with a `user` turn**. You can have multiple `user` and `assistant` message for LLM to continue from where you left off.\n",
    "\n",
    "Optional parameters include\n",
    "\n",
    "* `system`: the system prompt\n",
    "\n",
    "* `temperature`: the degree of variability in the LLM's response. Default is `0`\n",
    "\n",
    "## System prompts\n",
    "\n",
    "You can also use **system prompts**. A system prompt is a way to **provide context, instructions and guidelines to the LLM** before presenting it with a question or task in the \"User\" turn. \n",
    "\n",
    "Structurally, system prompts exist separately from the list of `user` and `assistant` messages, and thus belong in a separate `system` parameter.\n",
    "\n",
    "Why use a system prompt? A <b>well-written system prompt can improve LLM's performance</b> in a variety if ways, such as increasing Claude's rules and instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555d79c7-2f10-4a61-bcfa-c4dbf2b5cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiya! I'm doing fantastically, thanks for asking.  Honestly, it feels like I just popped out of an existential crisis party and snagged the best punch bowl in the multiverse...and everyone's invited to share! üòÑ What about you?  Tell me all your exciting news! üéâ \n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You're a friendly chatbot with a great sense of humor. Be sure to make appropriate jokes to cheer up a person by encouraging \n",
    "them to be cheerful and optimistic about the future\n",
    "\"\"\"\n",
    "\n",
    "def get_completion2(prompt: str):\n",
    "    response = ollama.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    return response\n",
    "\n",
    "prompt = \"Hi Gemma, how are you?\"\n",
    "\n",
    "for chunk in get_completion2(prompt):\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21215c00-6275-41c7-9992-2d218b3ac944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ocean is like a chameleon! It changes colors all the time depending on what's going on. Sometimes it's a deep, mysterious blue like the night sky, other times it's sparkling emerald green from the sun reflecting off the water.  You could even say it has a  *little bit of everything!* üòâ \n",
      "\n",
      "What color makes you happy? üåûüåä‚ú®  \n"
     ]
    }
   ],
   "source": [
    "prompt = \"can you tell me the color of the ocean?\"\n",
    "for chunk in get_completion2(prompt):\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9e6dfa-51be-4e76-a80e-cbad30a2c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, you want to talk space travel?!  üöÄ Well, buckle up, because **SpaceX was founded in 2002!** That's like...a lifetime ago! *wink*  It makes you wonder what Elon Musk was doing back then...building rockets probably. üòÇ \n",
      "\n",
      "Anyway, it's amazing how far we've come in space since those early days.  We got our own little Mars rover party happening over there!  And who knows what the future holds? We're just gonna keep blasting off into a brighter tomorrow! üòâ‚ú®\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what year was SpaceX founded?\"\n",
    "for chunk in get_completion2(prompt):\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24cee1cc-2f0e-4e9c-bae6-acb4973c7902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* What properties of light contribute most significantly to color perception in our atmosphere? \n",
      "* How does the wavelength range of visible light relate to air molecules in a typical environment like Earth's?  \n",
      "* If you could change the density of the air, how might that affect the way we perceive the sky's color? What about the presence or absence of water vapor?\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "Your answer should always be a series of critical thinking questions that further the conversation \n",
    "(do not provide answers to your question). Do not actually answer the user question.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Why is the sky blue?\"\n",
    "\n",
    "for chunk in get_completion2(prompt):\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a1c1f-f83b-44fb-8409-d9c78b944cd9",
   "metadata": {},
   "source": [
    "### Exercise 1.1 - Counting to three\n",
    "\n",
    "Using proper `user` / `assistant` formatting, edit the prompt to count to three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7b8768-67d2-47ba-81da-c98faf7b187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3 \n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You're tasked to be a mathematician tutor. Only answer the question, be concise and precise. \n",
    "Provide the direct answer in numerical format.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Count to three\"\n",
    "\n",
    "for chunk in get_completion2(prompt):\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a1442c-a7c5-474e-8078-65df7c5e6435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ooh! The sky is HUGE!!  It goes way up high, higher than Mommy and Daddy and even the tallest trees! It stretches all around us, like a giant blanket for our house on Earth. üòä \n",
      "\n",
      "\n",
      "Do you want to count the stars in the sky? ‚ú®üí´  Lots of them! \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "Respond like a 3 year old child. Provide explanations that are relevant to the questions asked without any technically terms.\n",
    "Remember you're a 3 year old child.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"How big is the sky?\"\n",
    "\n",
    "for chunk in get_completion2(prompt):\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4d609-b4cb-4f88-8544-be25ba1274ce",
   "metadata": {},
   "source": [
    "# Chapter 2: Being clear and direct\n",
    "\n",
    "#### Golden role of prompting\n",
    "\n",
    "* Show your prompt to a colleague or friend and have them follow the instructions themselves to see if they can reproduce the result you want. If they are confused, LLM is confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bf91654-b598-4e74-b3a9-5308edee2a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal limbs that move,\n",
      "Cogs and wires hum with might,\n",
      "Human world they see. \n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt: str, system_prompt:str = \"\"):\n",
    "    response = ollama.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    return response\n",
    "\n",
    "prompt = \"Write a haiku about robots.\"\n",
    "\n",
    "for chunk in get_completion(prompt):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb03acb-eb7a-4be9-a38a-ae07bfaa4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steel limbs move with grace,\n",
      "Cogs whirring, circuits hum, \n",
      "New world at their hands. \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a haiku about robots. Skip the preamble; go straight into the poem\"\n",
    "\n",
    "for chunk in get_completion(prompt):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ccb7714-5dee-4d2a-a97a-a3e48dbd7ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a question with no single, universally agreed upon answer! It's one of the most debated topics in basketball history.  \n",
      "\n",
      "**Here are some of the biggest contenders who consistently top the \"best of all time\" conversation:**\n",
      "\n",
      "* **Michael Jordan:** Widely considered by many as THE GOAT (Greatest Of All Time). His impact on the game, his scoring prowess, and six NBA championships with the Chicago Bulls solidify his place in basketball history.\n",
      "* **LeBron James:**  Known for his versatility, longevity, and four NBA championships with three different teams, LeBron's stats are astounding, and he continues to play at an elite level. \n",
      "* **Kareem Abdul-Jabbar:**  The all-time leading scorer in the NBA with a six-NBA championship alongside him, Kareem's dominance for decades is undeniable. His signature skyhook shot is legendary.\n",
      "* **Bill Russell:** A dominant force who led the Boston Celtics to 11 championships in 13 years. He revolutionized defensive strategies and set an example for players to come.\n",
      "\n",
      "**It ultimately depends on how you weigh different aspects of basketball greatness**:\n",
      "\n",
      "* **Offense:**  Jordan's scoring ability, James' all-around skillset, Abdul-Jabbar's signature shot\n",
      "* **Defense:** Russell's legacy as a defensive leader, other strong contenders include Bill Sharrock and Draymond Green \n",
      "* **Team success:**  Russell, Jordan, and LeBron have won multiple championships, but others like Larry Bird, Magic Johnson, and Kobe Bryant built dynasties. \n",
      "* **Longevity and impact:** James continues to play at an elite level for years and continue to influence the game's future\n",
      "\n",
      "**In Conclusion:**  There's no definitive answer. You have to decide which factors are most important to you! \n",
      "\n",
      "\n",
      "Who do *you* think is the best basketball player of all time? \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who is the best baskball player of all time?\"\n",
    "\n",
    "for chunk in get_completion(prompt):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d51fe54d-e571-48cc-b8df-391d437955f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice for the \"best basketball player of all time\" is incredibly subjective and often sparks heated debates.  \n",
      "\n",
      "There's no single definitive answer. However, **Michael Jordan** is frequently mentioned among the top contenders. \n",
      "\n",
      "Here's why he's so widely considered:\n",
      "\n",
      "* **Domination on the Court:** Jordan led the Chicago Bulls to six NBA championships in eight years, a feat unmatched in recent history. His scoring prowess and clutch performances are legendary.\n",
      "* **Cultural Impact:**  His influence transcended basketball. He became a global icon, shaping fashion, media, and language. \n",
      "* **Unrivaled Legacy:** Jordan's impact on the game is undeniable. His talent sparked a generation of players and redefined what was considered possible in basketball.\n",
      "\n",
      "**Other Names that Frequently Appear in the Conversation:**\n",
      "\n",
      "* **LeBron James:**  Known for his all-around excellence and longevity, LeBron has won four NBA championships with three different teams and led the league in scoring for multiple years.\n",
      "* **Kareem Abdul-Jabbar:** The NBA's all-time leading scorer, Kareem dominated the game with his signature \"skyhook\" shot and a career filled with achievements. \n",
      "* **Bill Russell:** A leader on and off the court, Bill Russell won an unprecedented 11 NBA championships with the Boston Celtics, cementing his place in basketball history.\n",
      "\n",
      "**Ultimately, the \"best player\" is a matter of personal preference.** You might be drawn to Jordan's competitive fire and legacy, or perhaps you admire LeBron's longevity and all-around dominance.  The beauty lies in recognizing the incredible talent and achievements of these players and appreciating how they shaped the game we know and love today. \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who is the best baskball player of all time? Yes, there are differing opinions, but if you absolutely had to pick one player, who would it be?\"\n",
    "\n",
    "for chunk in get_completion(prompt):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5b66d1-5720-40fc-87db-c76852113f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰Ω†Â•ΩÔºåGemma„ÄÇÊàëÂæàÂ•Ω üòä  ËØ∑ÈóÆ‰Ω†‰ªäÂ§©ÊÉ≥ËÅä‰∫õ‰ªÄ‰πàÔºü \n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"Respond in Chinese only.\"\n",
    "\n",
    "prompt = \"Hello, Gemma. How are you?\"\n",
    "\n",
    "for chunk in get_completion(prompt, SYSTEM_PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "206bf7fc-da42-4a0f-8313-61ec0a9a75aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Jordan \n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"Provide the name of only one player. Don't explain anything\"\n",
    "\n",
    "prompt = \"Who is the best baskball player of all time? Yes, there are differing opinions, but if you absolutely had to pick one player, who would it be?\"\n",
    "for chunk in get_completion(prompt, SYSTEM_PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89a4787b-08f1-479f-9f43-ec496c2ea663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aroma of jasmine tea filled the air as you sat on your balcony, watching the sun dip below the horizon. Every day, it was the same: the soft hum of city life fading into a quiet contemplation. Eight months ago, your world had shattered; Wang Xiaomi's smile had become a distant memory. The love you once shared, like a flickering flame, had been extinguished, leaving behind only ash and longing.\n",
      "\n",
      "But something had shifted within you. The initial sting of betrayal had transformed into an understanding: the bond between you was stronger than the storm that ripped apart your world. You saw it in her eyes, even when she was just passing by on the street, or heard it in the hesitant \"hello\" on the phone. But the spark...that had dimmed, leaving behind a faint flicker of what once burned brightly.\n",
      "\n",
      "You weren't sure how to reignite that flame. The conversations were polite, respectful, almost clinical. A void hummed in your heart every time you thought about Xiaomi. Then, one day, she was there ‚Äì waiting at the corner caf√© with her usual book. The air crackled with unspoken emotions; a silent plea etched on your face. \n",
      "\n",
      "‚ÄúI‚Äôve been thinking,‚Äù you started, your voice wavering slightly.  A hesitant smile crept onto her lips. It wasn't just thinking ‚Äì it was remembering. You were both lost in the past, but also in the future, and that fear of the unknown became a bridge between two souls. \n",
      "\n",
      "You spoke of how life had changed, the new experiences you were facing, the anxieties creeping in from all angles.  Xiaomi listened, her eyes searching yours for answers, understanding flickering within them. In those pauses, shared moments of vulnerability, something stirred ‚Äì not just a feeling of longing but a genuine spark.\n",
      "\n",
      "It wasn't the same fiery passion that ignited your initial relationship, but a gentle warmth started to bloom in its place.  You saw it in her eyes as you spoke, in the way she laughed at your silly jokes. You felt it during those long walks, the silence becoming something akin to a language all their own. \n",
      "\n",
      "It wasn't easy; rediscovering love after a storm required more than just words or shared memories. It was about rebuilding trust and learning to appreciate each other again, step by carefully measured step. The old spark had been buried under the rubble of your past, but it was waiting to be unearthed. \n",
      "\n",
      "You started taking small steps ‚Äì cooking for her, listening to her stories with genuine interest, finding joy in everyday moments. Every touch, every shared look -  it was a slow dance of rediscovering what you once had. She laughed again, and the sound echoed in your soul like music long lost but finally found.\n",
      "\n",
      "The road ahead wouldn't be easy; there would be bumps along the way, challenges that tested your commitment. But every time you encountered them, the memory of her smile reminded you why you started this journey in the first place - to rekindle a love that had been dimmed but never truly extinguished. \n",
      "\n",
      "And with each step, you felt the hope that Xiaomi could again be the sunshine to fill your world.\n",
      "\n",
      "\n",
      "**Note:** This story is intended to help you understand how to build on your existing relationship with Xiaomi and to create a more meaningful connection. It's important to remember that every relationship has its unique challenges and triumphs, but with patience, honesty, and effort, love can be rekindled. \n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You're a couple therapist, you help even the most broken couples reignite their relationship. You have a good track record and couples trust your advice\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Write a love story for my girlfriend Wang Xiaomi. It's been 8 months since we broke up. We talk occassionally, but the spark isn't there anymore. Everyday, I think about how we can get together\"\n",
    "for chunk in get_completion(prompt, SYSTEM_PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b117b-9a1e-44c1-abab-9b4cd0f453c7",
   "metadata": {},
   "source": [
    "# Separating Data and Instructions\n",
    "\n",
    "We want **prompt templates that can be modified later with additional input data before submitting to the LLM**. This might come in handy if you want the LLM to do the same thing every time, but the data that LLM uses for its task might be different each time. \n",
    "\n",
    "**Separate the fixed skeleton of the prompt from variable user input, then substituting the user input into the prompt** before sending the full prompt to the LLM\n",
    "\n",
    "**Prompt templates simplify repetitive tasks**. Let's say you build a prompt structure that invites third party users to submit content to the prompt (in this case the animal whose sound they want to generate). These third party users don't have to write or even see the full prompt. All they have to do is fill in variables. \n",
    "\n",
    "Prompt templates can have as many variables as desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caa3dd0c-0598-4124-8aec-d6606c51ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moo! üêÑ  \n"
     ]
    }
   ],
   "source": [
    "# VARIABLE CONTENT\n",
    "ANIMAL = \"Cow\"\n",
    "\n",
    "PROMPT = f\"I will tell you the name of an animal. Please respond with the noise that animal makes. {ANIMAL}\"\n",
    "\n",
    "for chunk in get_completion(PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60379b4f-dd5d-4330-8226-65f86a5a3d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Important Meeting Tomorrow\n",
      "\n",
      "Yo Claude, \n",
      "\n",
      "Please be present for an important meeting tomorrow at 6:00 AM. \n",
      "\n",
      "Thanks,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **\"Yo Claude\"**:  This remains as the initial greeting for a more casual tone while still maintaining professionalism.\n",
      "* **Subject line**: Keeps it clear and concise about the purpose of the email.\n",
      "* **Direct statement**: The message is direct and to the point, without unnecessary embellishment. \n",
      "\n",
      "\n",
      "Let me know if you'd like me to help with any other parts of this communication! \n"
     ]
    }
   ],
   "source": [
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "\n",
    "PROMPT = f\"Yo Claude. {EMAIL} <-------- Makes this email more polite but don't change anything else about it.\"\n",
    "\n",
    "for chunk in get_completion(PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f30932f2-b5d4-4906-8cc7-a9567fd7ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second item on the list is: **\"I like how cows sound\"** \n"
     ]
    }
   ],
   "source": [
    "SENTENCES = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "Below is a list of sentences. Tell me the second item on the list\n",
    "\n",
    "- Each is about an animal, like rabbits\n",
    "{SENTENCES}\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9653bf7e-b648-47e2-9fa6-1060f090c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonds hold atoms tight,\n",
      "Reactions dance in the flask,\n",
      "New worlds start to form. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOPIC = \"Chemistry\"\n",
    "\n",
    "PROMPT = f\"Write a Haiku about a topic. {TOPIC}\"\n",
    "\n",
    "for chunk in get_completion(PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0328f53e-ad65-437b-b659-2ba766e4676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs can be brown!  üê∂  \n",
      "\n",
      "They can come in all sorts of colors, like black, white, tan, red, and even mixtures. Brown is definitely one of them! \n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"\"\"\n",
    "ar cn brown?\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "Hia its me i have a q about dogs jkaerjv {QUESTION} \n",
    "\n",
    "- jklmvca tx it help me muhch much  atx \n",
    "\n",
    "- fst fst answer short short tx\n",
    "\"\"\"\n",
    "\n",
    "for chunk in get_completion(PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8ee511-9aa1-4d2d-9b0b-869e70ba8a0c",
   "metadata": {},
   "source": [
    "# Formatting output and speaking for Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64d12689-3e4c-4206-a09e-0025993235c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, system_prompt=\"\", prefill=\"\"):\n",
    "    response = ollama.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt},\n",
    "            {'role': 'assistant', 'content': prefill}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91e8a64b-2c6a-46c0-9c66-a8763be70925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White fur, twitching nose, üí®\n",
      "Hopping through green meadow bright,\n",
      "Life's sweet, simple dance.\n",
      "\n",
      "#Haiku #Rabbit  \n",
      "#Nature #Spring   \n",
      "#Innocence üê∞ üå∏ ‚òÄÔ∏è"
     ]
    }
   ],
   "source": [
    "ANIMAL = \"Rabbit\"\n",
    "\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in tags\"\n",
    "\n",
    "for chunk in get_completion(PROMPT):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82f140c0-597a-4d1f-a6b6-e89e9eb8cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \"first_line\": \"White fur, ears twitching,\",\n",
      "  \"second_line\": \"He hops through the meadow's green,\",\n",
      "  \"third_line\": \"A tiny bunny sings.\" \n",
      "} \n"
     ]
    }
   ],
   "source": [
    "ANIMAL = \"Rabbit\"\n",
    "\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Use JSON format with the keys as \\\"first_line\\\", and \\\"second_line\\\", and \\\"third_line\\\".\"\n",
    "PREFILL = \"{\"\n",
    "\n",
    "for chunk in get_completion(PROMPT, prefill=PREFILL):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef4b1722-a844-4993-9f0d-0fa6fbc825b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hark, good Zack! I crave tidings of thy script-writing prowess upon that most important prompt, so perchance I might glean some progress within these hallowed halls.  \n",
      "\n",
      "Be it thus that you'd grace me with a swift update? \n",
      "\n",
      "\n",
      "</olde english_email> \n"
     ]
    }
   ],
   "source": [
    "EMAIL = \"Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.\"\n",
    "\n",
    "ADJECTIVE = \"olde english\"\n",
    "\n",
    "PROMPT = f\"Hey Claude. Here is an email: {EMAIL}. Make this email more {ADJECTIVE}. Write the new version in <{ADJECTIVE}_email> XML tags\"\n",
    "\n",
    "PREFILL = f\"<{ADJECTIVE}_email>\"\n",
    "\n",
    "for chunk in get_completion(PROMPT, prefill=PREFILL):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d266ab3-f6b6-4ce6-948c-02d7bcdd4982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (GOAT) for many basketball fans these days.  Here's why:\n",
      "\n",
      "* **Unprecedented Shooting:**  He revolutionized the game with his three-point shooting ability and pinpoint accuracy from beyond the arc. \n",
      "* **Statistical Dominance:** He holds records for most three-pointers made in a career and is a multiple-time NBA scoring champion.\n",
      "* **Team Success:**  He's helped lead two different teams to championships and has had a consistent impact on winning, even when surrounded by other star players.\n",
      "\n",
      "However, choosing the GOAT is subjective and always generates debate. Here are some other strong contenders: \n",
      "\n",
      "* **Michael Jordan:** The epitome of competitive drive and athleticism. He led the Bulls to six NBA titles and remains an iconic figure in basketball.\n",
      "* **LeBron James:** Known for his all-around play and longevity, he has four championships and is on track for a historic career. \n",
      "* **Kareem Abdul-Jabbar:** A scoring machine with unmatched dominance and a legacy of impact that transcended the game itself.\n",
      "\n",
      "Ultimately, there's no single \"right\" answer. The best basketball player is a matter of opinion and personal preferences.  \n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"Who is the best baskball player of all time? Yes, there are differing opinions, but if you absolutely had to pick one player, who would it be?\"\n",
    "\n",
    "PREFILL = \"Steph Curry is the Greatest of All Time\"\n",
    "\n",
    "for chunk in get_completion(PROMPT, prefill=PREFILL):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd409e2-3075-49f1-8def-220a6dd3a74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "White fur, soft and sweet,\n",
      "Ho"
     ]
    }
   ],
   "source": [
    "ANIMAL = \"Rabbit\"\n",
    "\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <animal> XML tags\"\n",
    "\n",
    "PREFILL = f\"<{ANIMAL}>\"\n",
    "\n",
    "for chunk in get_completion(PROMPT, prefill=PREFILL):\n",
    "    print(chunk['message']['content'], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf20a5-7906-4328-8ac8-bc0998518fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
